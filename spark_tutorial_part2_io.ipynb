{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Spark SQL and DataFrames\n",
    "\n",
    "Author: **Julien Peloton** [@JulienPeloton](https://github.com/astrolabsoftware/spark-tutorials/issues/new?body=@JulienPeloton)  \n",
    "Last Verifed to Run: **2018-10-25**  \n",
    "\n",
    "__Learning objectives__\n",
    "\n",
    "- A tour of data formats.\n",
    "- Loading and distributing data: Spark SQL and DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A tour of data formats\n",
    "\n",
    "There are many data formats used in the context of Big Data: CSV (1978), XML (1996), JSON (2001), Thrift (2007), Protobuf (2008), Avro & SequenceFile (2009), Parquet (2013), ORC (2016), and the list goes on... Some are _naively_ structured that is using a single type to describe the data (e.g. text) or repeating the same <...>. Others are complex and highly optimised for big data treatment. \n",
    "\n",
    "Spark interface is sufficiently well written to allow extending it easily and write connector for any kind of data source.\n",
    "\n",
    "Before and now: Data Source v1. Now: Data Source v2.\n",
    "\n",
    "But the point is that none are used in astronomy for the moment! Efforts done: Spark-fits, hdf5 (but Scala only), ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JVM limit: 2G points!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and distributing data: Spark SQL and DataFrames\n",
    "\n",
    "The interface to read data from disk is always the same for any kind of built-in and officially supported data format:\n",
    "\n",
    "```python\n",
    "df = spark.read\\\n",
    "    .format(format: str)\\\n",
    "    .option(key: str, value: Any)\\\n",
    "    # ...\n",
    "    .option(key: str, value: Any)\\\n",
    "    .load(path: str)\n",
    "```\n",
    "\n",
    "### Format\n",
    "\n",
    "The format can be \"csv\", \"json\", \"parquet\", etc. \n",
    "\n",
    "### Options \n",
    "\n",
    "The options are specific to each format. In most of the case, no options are needed, but you might want to explore the different possibilities at some point. \n",
    "\n",
    "### Path\n",
    "\n",
    "The path to the data is "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
