# Learning Apache Spark by the example

Welcome to the series of notebooks on Apache Spark! The main goal of this series is to get familiar with Apache Spark, and in particular its Python API called PySpark. It is by no means complete, and
I might have done many errors, left many typos, and some parts might be deprecated. Feel free to open an issue ([@JulienPeloton](https://github.com/astrolabsoftware/spark-tutorials/issues/new?body=@JulienPeloton)) if this is the case!

## Table of content:

- Part I: Installation and first steps
    - Apache Spark: what it is?
    - Installation @ HOME
    - Using the PySpark shell
    - Your first Spark program.
- Part II: Spark SQL and DataFrames
    - A tour of data formats.
    - Loading and distributing data: Spark SQL and DataFrames.
- Part III: Data manipulation


- Appendix A: Apache Spark @ NERSC
    - Apache Spark and HPC machines.
    - Batch jobs @ NERSC
    - JupyterLab @ NERSC

## Bibliography and useful links

### Bibliography

- Databricks: [Research papers](https://databricks.com/resources/type/research-papers/page/2) on Apache Spark (e.g. [foundation](https://pages.databricks.com/rs/094-YMS-629/images/hotcloud_spark.pdf), [rdd](https://pages.databricks.com/rs/094-YMS-629/images/nsdi_spark.pdf))
- HDFS: [The Hadoop distributed file system](http://storageconference.us/2010/Papers/MSST/Shvachko.pdf).
- Scientific Spark: [spark-fits](https://arxiv.org/abs/1804.07501), [Apache Spark for physicists](https://arxiv.org/abs/1807.03078) + see bibliography at the end of those papers.
- Books: Spark, Scala.

### Links

- Apache Spark documentation: https://spark.apache.org/docs/latest/
