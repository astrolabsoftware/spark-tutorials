{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Apache Spark by the example\n",
    "\n",
    "Author: **Julien Peloton** [@JulienPeloton](https://github.com/JulienPeloton)  \n",
    "Last Verifed to Run: **2018-10-25**  \n",
    "\n",
    "Welcome to the series of notebooks on Apache Spark! The main goal of this series is to get familiar with Apache Spark, and in particular its Python API called PySpark. It is by no means complete, and\n",
    "I might have done many errors, left many typos, and some parts might be deprecated. Feel free to open an issue ([@JulienPeloton](https://github.com/astrolabsoftware/spark-tutorials/issues/new?body=@JulienPeloton)) if this is the case!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of content:\n",
    "\n",
    "- Part I: Installation and first steps\n",
    "    - Apache Spark: what it is?\n",
    "    - Installation @ HOME\n",
    "    - Using the PySpark shell\n",
    "    - Your first Spark program.\n",
    "    - Bibliography and useful links\n",
    "- Part II: Apache Spark @ NERSC\n",
    "    - Apache Spark and HPC machines.\n",
    "    - Batch jobs @ NERSC\n",
    "    - JupyterLab @ NERSC\n",
    "- Part III: Spark SQL and DataFrames\n",
    "    - A tour of data formats.\n",
    "    - Loading and distributing data: Spark SQL and DataFrames.\n",
    "- Part IV: Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
